{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Thread safe**\n",
    "\n",
    "### **Definition**\n",
    "\n",
    "Thread safety is a computer programming concept applicable to multi-threaded code. Thread-safe code only manipulates shared data structures in a manner that ensures that all threads behave properly and fulfill their design specifications without unintended interaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python threading example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "def threadFun(a, b):\n",
    "    print(a,b)\n",
    "\n",
    "\n",
    "t = threading.Thread(target=threadFun, args=(100, 200,))\n",
    "\n",
    "t.start()\n",
    "t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "\n",
    "urls = [f\"https://ww.cnblogs.com/#p{page}\" for page in range(1, 50+1)]\n",
    "\n",
    "def parseHtml(html):\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    links = soup.find_all(\"a\",class_=\"post-item-title\")\n",
    "    return [(link['href'],link.get_text()) for link in links  ]\n",
    "\n",
    "\n",
    "def craw(url):\n",
    "    # r = requests.get(url)\n",
    "    # parseHtml(r)\n",
    "    # print(url, len(r.text))\n",
    "    return requests.get(url).text\n",
    "\n",
    "def mul():\n",
    "    threads = [threading.Thread(target=craw, args=(url,)) for url in urls]\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "        \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "# mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import queue\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def do_craw(urlqueue:queue.Queue, htmlqueue:queue.Queue):\n",
    "    while True:\n",
    "        url = urlqueue.get()\n",
    "        html = craw(url)\n",
    "        htmlqueue.put(html)\n",
    "        print(threading.current_thread().name,\n",
    "              f\"crawl {url}\", \"URL queue size\", urlqueue.qsize())\n",
    "        time.sleep(random.randint(1, 2))\n",
    "\n",
    "\n",
    "def do_parse(htmlqueue:queue.Queue, fileout):\n",
    "    while True:\n",
    "        html = htmlqueue.get()\n",
    "        res = parseHtml(html)\n",
    "        for re in res:\n",
    "            fileout.write(str(re)+\"\\n\")\n",
    "        print(threading.current_thread().name,\n",
    "              f\"crawl {url}\", \"res queue size\",len(res),\n",
    "              f\"html queue size\", htmlqueue.qsize())\n",
    "        time.sleep(random.randint(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "craw 1 crawl https://ww.cnblogs.com/#p2 URL queue size 48\n",
      "craw 0 crawl https://ww.cnblogs.com/#p1 URL queue size 48\n",
      "craw 0 crawl https://ww.cnblogs.com/#p3 URL queue size 47\n",
      "craw 1 crawl https://ww.cnblogs.com/#p4 URL queue size 46\n",
      "craw 0 crawl https://ww.cnblogs.com/#p5 URL queue size 45\n",
      "craw 1 crawl https://ww.cnblogs.com/#p6 URL queue size 44\n",
      "craw 1 crawl https://ww.cnblogs.com/#p7 URL queue size 42\n",
      "craw 0 crawl https://ww.cnblogs.com/#p8 URL queue size 42\n",
      "craw 1 crawl https://ww.cnblogs.com/#p9 URL queue size 40\n",
      "craw 0 crawl https://ww.cnblogs.com/#p10 URL queue size 40\n",
      "craw 1 crawl https://ww.cnblogs.com/#p11 URL queue size 39\n",
      "craw 0 crawl https://ww.cnblogs.com/#p12 URL queue size 38\n",
      "craw 1 crawl https://ww.cnblogs.com/#p13 URL queue size 36\n",
      "craw 0 crawl https://ww.cnblogs.com/#p14 URL queue size 36\n",
      "craw 1 crawl https://ww.cnblogs.com/#p15 URL queue size 34\n",
      "craw 0 crawl https://ww.cnblogs.com/#p16 URL queue size 34\n",
      "craw 0 crawl https://ww.cnblogs.com/#p17 URL queue size 33\n",
      "craw 1 crawl https://ww.cnblogs.com/#p18 URL queue size 32\n",
      "craw 0 crawl https://ww.cnblogs.com/#p19 URL queue size 31\n",
      "craw 1 crawl https://ww.cnblogs.com/#p20 URL queue size 30\n",
      "craw 0 crawl https://ww.cnblogs.com/#p21 URL queue size 29\n",
      "craw 1 crawl https://ww.cnblogs.com/#p22 URL queue size 28\n",
      "craw 0 crawl https://ww.cnblogs.com/#p23 URL queue size 27\n",
      "craw 0 crawl https://ww.cnblogs.com/#p24 URL queue size 26\n",
      "craw 1 crawl https://ww.cnblogs.com/#p25 URL queue size 25\n",
      "craw 1 crawl https://ww.cnblogs.com/#p26 URL queue size 24\n",
      "craw 0 crawl https://ww.cnblogs.com/#p27 URL queue size 23\n",
      "craw 0 crawl https://ww.cnblogs.com/#p28 URL queue size 22\n",
      "craw 1 crawl https://ww.cnblogs.com/#p29 URL queue size 21\n",
      "craw 0 crawl https://ww.cnblogs.com/#p30 URL queue size 20\n",
      "craw 1 crawl https://ww.cnblogs.com/#p31 URL queue size 19\n",
      "craw 1 crawl https://ww.cnblogs.com/#p32 URL queue size 17\n",
      "craw 0 crawl https://ww.cnblogs.com/#p33 URL queue size 17\n",
      "craw 1 crawl https://ww.cnblogs.com/#p34 URL queue size 15\n",
      "craw 0 crawl https://ww.cnblogs.com/#p35 URL queue size 15\n",
      "craw 1 crawl https://ww.cnblogs.com/#p36 URL queue size 13\n",
      "craw 0 crawl https://ww.cnblogs.com/#p37 URL queue size 13\n",
      "craw 1 crawl https://ww.cnblogs.com/#p38 URL queue size 11\n",
      "craw 0 crawl https://ww.cnblogs.com/#p39 URL queue size 11\n",
      "craw 1 crawl https://ww.cnblogs.com/#p40 URL queue size 10\n",
      "craw 0 crawl https://ww.cnblogs.com/#p42 URL queue size 8\n",
      "craw 1 crawl https://ww.cnblogs.com/#p41 URL queue size 8\n",
      "craw 1 crawl https://ww.cnblogs.com/#p43 URL queue size 6\n",
      "craw 0 crawl https://ww.cnblogs.com/#p44 URL queue size 6\n",
      "craw 1 crawl https://ww.cnblogs.com/#p45 URL queue size 4\n",
      "craw 0 crawl https://ww.cnblogs.com/#p46 URL queue size 4\n",
      "craw 1 crawl https://ww.cnblogs.com/#p47 URL queue size 2\n",
      "craw 0 crawl https://ww.cnblogs.com/#p48 URL queue size 2\n",
      "craw 1 crawl https://ww.cnblogs.com/#p49 URL queue size 0\n",
      "craw 0 crawl https://ww.cnblogs.com/#p50 URL queue size 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    urlqueue = queue.Queue()\n",
    "    htmlqueue = queue.Queue()\n",
    "    for url in urls:\n",
    "        urlqueue.put(url)\n",
    "\n",
    "    for idx in range(2):\n",
    "        t = threading.Thread(\n",
    "            target=do_craw,\n",
    "            args=(urlqueue, htmlqueue),\n",
    "            name=f\"craw {idx}\")\n",
    "        t.start()\n",
    "\n",
    "    # fout = open(\"crawl.txt\", \"w\")\n",
    "    # for idx in range(4):\n",
    "    #     t = threading.Thread(\n",
    "    #         target=do_parse,\n",
    "    #         args=(urlqueue, htmlqueue),\n",
    "    #         name=f\"craw {idx}\")\n",
    "    #     t.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-1ad9fec2eeaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\asyncio\\runners.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         raise RuntimeError(\n\u001b[0m\u001b[0;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def task1():\n",
    "    print(\"Send first email\")\n",
    "    # asyncio.create_task(task2())\n",
    "    await asyncio.sleep(5)\n",
    "    print(\"First Email reply\")\n",
    "\n",
    "\n",
    "async def task2():\n",
    "    print(\"Send second email\")\n",
    "    asyncio.create_task(task3())\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Second Email reply\")\n",
    "\n",
    "\n",
    "async def task3():\n",
    "    print(\"Send third email\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Third Email reply\")\n",
    "\n",
    "\n",
    "asyncio.run(task1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
